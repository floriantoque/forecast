{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF INVERTED - multi/uni -> MULTI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../utils/')\n",
    "from utils import *\n",
    "from pylab import *\n",
    "from utils_date import *\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_xy_dataset(df_Xy, time_series, features_exogenous, features_context):\n",
    "    df_Xy = copy.deepcopy(df_Xy[time_series+features_exogenous+features_context].dropna())\n",
    "    days = sorted(list(set([i[:10] for i in df_Xy.index.values])))\n",
    "    Xnames = [f+'-T'+str(ix)for f in features_exogenous for ix in np.arange(96)] + features_context\n",
    "    \n",
    "    X = []\n",
    "    list_y=[]\n",
    "    for d in tqdm(days,desc='Days loop'):\n",
    "        ex = df_Xy.loc[d+' 00:00:00': d+ ' 23:45:00'][features_exogenous].values.T.flatten()\n",
    "        co = df_Xy.loc[[d+' 00:00:00']][features_context].values.flatten()\n",
    "        X.append(np.concatenate([ex, co]))\n",
    "        y = []\n",
    "        for s in time_series:\n",
    "            y.append(df_Xy.loc[d+' 00:00:00': d+ ' 23:45:00'][s].values)\n",
    "        list_y.append(y)\n",
    "    list_y = np.array(list_y)\n",
    "        \n",
    "\n",
    "    return np.array(X), list_y.reshape(list_y.shape[0],list_y.shape[1]*list_y.shape[2]), Xnames, days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AT=5\n",
    "def mse(obs, pred):\n",
    "    return ((pred - obs) ** 2).mean()\n",
    "\n",
    "def rmse(obs, pred):\n",
    "    return np.sqrt(mse(obs, pred))\n",
    "\n",
    "def mae(obs, pred):\n",
    "    return np.absolute(pred - obs).mean()\n",
    "\n",
    "def mape_at(obs, pred):\n",
    "    mask = obs >= AT\n",
    "    return ((np.absolute(pred[mask] - obs[mask]) / obs[mask]).mean())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_predict(X, y, cv, param_grid, scaler_choice_X, scaler_choice_y):\n",
    "    \n",
    "    pred_train_array = []\n",
    "    pred_val_array = []\n",
    "    ytrain_array = []\n",
    "    yval_array = []\n",
    "    \n",
    "    for ix_train,ix_val in cv.split(X):\n",
    "        Xtrain,Xval = X[ix_train], X[ix_val]\n",
    "        ytrain,yval = y[ix_train], y[ix_val]\n",
    "\n",
    "        scalerX = None\n",
    "        scalery = None\n",
    "        if scaler_choice_X == 'minmax':\n",
    "            scalerX = MinMaxScaler(feature_range=(0, 1))\n",
    "        elif scaler_choice_X == 'standard':\n",
    "            scalerX = StandardScaler()\n",
    "        if scalerX != None:\n",
    "            Xtrain = scalerX.fit_transform(Xtrain)\n",
    "            Xval = scalerX.transform(Xval)\n",
    "\n",
    "        if scaler_choice_y == 'minmax':\n",
    "            scalery = MinMaxScaler(feature_range=(0, 1))\n",
    "        elif scaler_choice_y == 'standard':\n",
    "            scalery = StandardScaler()\n",
    "        if scalery != None:\n",
    "            ytrain = scalery.fit_transform(ytrain)\n",
    "            yval = scalery.transform(yval)\n",
    "\n",
    "        keys, values = zip(*param_grid.items())\n",
    "        all_params = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "        pred_train_params = []\n",
    "        pred_val_params = []\n",
    "        for p in all_params:\n",
    "            rf = RandomForestRegressor(**p, verbose=0)\n",
    "            rf.fit(Xtrain,ytrain)\n",
    "            pred_train = rf.predict(Xtrain)\n",
    "            pred_val = rf.predict(Xval)\n",
    "            pred_train_params.append(pred_train)\n",
    "            pred_val_params.append(pred_val)\n",
    "\n",
    "        pred_train_array.append(pred_train_params)\n",
    "        pred_val_array.append(pred_val_params)\n",
    "        ytrain_array.append(ytrain)\n",
    "        yval_array.append(yval)\n",
    "\n",
    "    pred_train_array = np.array(pred_train_array)\n",
    "    pred_val_array = np.array(pred_val_array)\n",
    "    ytrain_array = np.array(ytrain_array)\n",
    "    yval_array = np.array(yval_array) \n",
    "    \n",
    "    return pred_train_array, pred_val_array, ytrain_array, yval_array\n",
    "\n",
    "\n",
    "def optimize(X, y, param_kfold, time_series):\n",
    "\n",
    "    cv = KFold(**param_kfold)\n",
    "\n",
    "\n",
    "    pred_train, pred_val, obs_train, obs_val = fit_predict(X, y, cv, param_grid, scaler_choice_X,\n",
    "                                                                                 scaler_choice_y)\n",
    "   \n",
    "\n",
    "    errors_function = [rmse, mse, mae, mape_at]\n",
    "    errors_name = ['rmse', 'mse', 'mae', 'mape_at']\n",
    "    grid_search_dict={'train':{}, 'val':{}}\n",
    "    for ef,en in zip(errors_function, errors_name):\n",
    "\n",
    "        grid_search_dict['train'][en]={}\n",
    "        grid_search_dict['train'][en]['error'] = np.array([np.array([ef(np.concatenate(pred_train[ixcv][ixp]), np.concatenate(obs_train[ixcv])) \n",
    "                            for ixcv in range(pred_train.shape[0])]) for ixp in range(pred_train.shape[1])])\n",
    "\n",
    "        grid_search_dict['train'][en]['mean'] = grid_search_dict['train'][en]['error'].mean(axis=1) \n",
    "        grid_search_dict['train'][en]['std'] = grid_search_dict['train'][en]['error'].std(axis=1) \n",
    "\n",
    "        grid_search_dict['val'][en]={}\n",
    "        grid_search_dict['val'][en]['error'] = np.array([np.array([ef(np.concatenate(pred_val[ixcv][ixp]), np.concatenate(obs_val[ixcv])) \n",
    "                            for ixcv in range(pred_val.shape[0])]) for ixp in range(pred_val.shape[1])])\n",
    "\n",
    "        grid_search_dict['val'][en]['mean'] = grid_search_dict['val'][en]['error'].mean(axis=1) \n",
    "        grid_search_dict['val'][en]['std'] = grid_search_dict['val'][en]['error'].std(axis=1) \n",
    "\n",
    "    return grid_search_dict\n",
    "\n",
    "\n",
    "def pred_list_to_dataframe(pred_list, time_series, days):\n",
    "    data = [j for i in [build_timestamp_list(d+' 00:00:00', d+ ' 23:45:00') for d in days] for j in i]\n",
    "    df = pd.DataFrame(data=data, columns=['Datetime'])\n",
    "    for ix, ts in enumerate(time_series):\n",
    "        df[ts] = pred_list[ix].reshape(pred_list[ix].shape[0]*pred_list[ix].shape[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "observation_data_path = ['/home/toque/data2/montreal/stm/data/valid_metro_15min_2015_2016_2017_sumpass_nodayfree.csv']\n",
    "exogenous_data_path = ['/home/toque/data2/montreal/events/data/clean/events_2015_2018_end_event_stopid.csv',\n",
    "                       '/home/toque/data2/montreal/events/data/clean/events_2015_2018_start_event_stopid.csv',\n",
    "                       '/home/toque/data2/montreal/events/data/clean/events_2015_2018_period_event_stopid.csv',\n",
    "                       '/home/toque/data2/weather/predicted_weather/predicted_weather_2015_2017_included_perday_pm.csv'\n",
    "                      ]\n",
    "context_data_path = ['/home/toque/data2/date/2013-01-01-2019-01-01_new.csv']\n",
    "\n",
    "df_observation = read_csv_list(observation_data_path)\n",
    "df_exogenous = read_csv_list(exogenous_data_path)\n",
    "df_context = read_csv_list(context_data_path)\n",
    "\n",
    "# fill timestamps not available with 0 to have 96 timestamps per day\n",
    "days = sorted(list(set([i[:10] for i in df_observation['Datetime'].values])))\n",
    "timestamp_list = [j for i in [build_timestamp_list(d+' 00:00:00', d+' 23:45:00', time_step_second=15*60) for d in days] for j in i]\n",
    "df_date = pd.DataFrame(data = timestamp_list, columns = ['Datetime']).set_index('Datetime')\n",
    "df_observation = df_date.join(df_observation.set_index('Datetime')).fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_series = ['11', '32', '34', '15', '44', '65', '31', '33', '35', '47', '13',\n",
    "       '14', '1', '9', '5', '18', '36', '24', '68', '43', '8', '64', '10',\n",
    "       '55', '3', '49', '51', '2', '19', '56', '7', '6', '4', '48', '66',\n",
    "       '25', '23', '28', '39', '54', '60', '27', '20', '46', '12', '21',\n",
    "       '62', '52', '41', '50', '30', '16', '37', '40', '26', '67', '57',\n",
    "       '61', '42', '45', '38', '29', '58', '63', '22', '59', '53', '17']\n",
    "\n",
    "features_exogenous = ['5-end_event', '11-end_event', '12-end_event', '13-end_event',\n",
    "       '15-end_event', '16-end_event', '23-end_event', '24-end_event',\n",
    "       '31-end_event', '32-end_event', '35-end_event', '43-end_event',\n",
    "       '45-end_event', '61-end_event', '68-end_event', '5-start_event',\n",
    "       '11-start_event', '12-start_event', '13-start_event',\n",
    "       '15-start_event', '16-start_event', '23-start_event',\n",
    "       '24-start_event', '31-start_event', '32-start_event',\n",
    "       '35-start_event', '43-start_event', '45-start_event',\n",
    "       '61-start_event', '68-start_event', '5-period_event',\n",
    "       '11-period_event', '12-period_event', '13-period_event',\n",
    "       '15-period_event', '16-period_event', '23-period_event',\n",
    "       '24-period_event', '31-period_event', '32-period_event',\n",
    "       '35-period_event', '43-period_event', '45-period_event',\n",
    "       '61-period_event', '68-period_event']\n",
    "\n",
    "features_context = ['Day_id', 'Mois_id','vac_noel_quebec', 'day_off_quebec', '24DEC', '31DEC',\n",
    "                    'renov_beaubien', 'vac_udem1', 'vac_udem2']\n",
    "\n",
    "scaler_choice_X = None\n",
    "scaler_choice_y = None\n",
    "\n",
    "param_kfold={\n",
    "    'n_splits': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': 1}\n",
    "\n",
    "param_grid={\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_features': ['auto',None],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1,5,10],\n",
    "    'n_jobs': [6],\n",
    "    'criterion': ['mse']}\n",
    "\n",
    "param_kfold={\n",
    "    'n_splits': 3,\n",
    "    'shuffle': True,\n",
    "    'random_state': 1}\n",
    "\n",
    "param_grid={\n",
    "    'n_estimators': [10,40],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'n_jobs': [6],\n",
    "    'criterion': ['mse']}\n",
    "\n",
    "time_series = ['11', '32', '34', '15']\n",
    "\n",
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2015-12-31 23:45:00'\n",
    "\n",
    "model_name = 'rf_multi_inverted_event15'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 365/365 [00:00<00:00, 473.88it/s]\n"
     ]
    }
   ],
   "source": [
    "df_Xy = df_observation.set_index('Datetime').join([df_context.set_index('Datetime'), df_exogenous.set_index('Datetime')])\n",
    "\n",
    "df_Xy_train = df_Xy[start_datetime:end_datetime]\n",
    "Xtrain, ytrain, Xnames, days = create_xy_dataset(df_Xy_train, time_series, features_exogenous, features_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 2)\n",
      "(3,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "grid_search_dict = optimize(Xtrain, ytrain, param_kfold, time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_pickle('/home/toque/data2/forecast/model/rf_multi_inverted/optimize/'+model_name+'/grid_search_dict.pkl', grid_search_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get best params and learn with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_dict = load_pickle('/home/toque/data2/forecast/model/rf_multi_inverted/optimize/'+model_name+'/grid_search_dict.pkl')\n",
    "\n",
    "best_arg = grid_search_dict['val']['rmse']['mean'].argmin()\n",
    "keys, values = zip(*param_grid.items())\n",
    "all_params = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "best_params = all_params[best_arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 365/365 [00:00<00:00, 489.74it/s]\n"
     ]
    }
   ],
   "source": [
    "df_Xy = df_observation.set_index('Datetime').join([df_context.set_index('Datetime'), df_exogenous.set_index('Datetime')])\n",
    "df_Xy_train = df_Xy[start_datetime:end_datetime]\n",
    "Xtrain, ytrain, Xnames, days = create_xy_dataset(df_Xy_train, time_series, features_exogenous, features_context)\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(**best_params, verbose=0)\n",
    "rf = rf.fit(Xtrain,ytrain)\n",
    "\n",
    "    \n",
    "# Save models\n",
    "#save_pickle('/home/toque/data2/forecast/model/rf_uni_inverted/optimize/'+model_name+'/list_rf_uni_inverted.pkl', rf_list)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 1093/1093 [00:02<00:00, 430.49it/s]\n"
     ]
    }
   ],
   "source": [
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2017-12-31 23:45:00'\n",
    "df_Xy = df_observation.set_index('Datetime').join([df_context.set_index('Datetime'), df_exogenous.set_index('Datetime')])\n",
    "df_Xy_test = df_Xy[start_datetime:end_datetime]\n",
    "\n",
    "Xtest, ytest, Xnames, days_test = create_xy_dataset(df_Xy_test, time_series, features_exogenous, features_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_directory_to_save = '/home/toque/data2/forecast/model/rf_multi_inverted/prediction/'+model_name+'/'\n",
    "\n",
    "res = rf.predict(Xtest)\n",
    "res = res.reshape(res.shape[0], len(time_series), 96)\n",
    "\n",
    "res = np.swapaxes(res, 0,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_res = pred_list_to_dataframe(res, time_series, days_test)\n",
    "\n",
    "if not os.path.exists(path_directory_to_save):\n",
    "     os.makedirs(path_directory_to_save)\n",
    "\n",
    "df_res.to_csv(path_directory_to_save + start_datetime[:10] + \"_\" + end_datetime[:10] + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [02:08<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "p= {'criterion': 'mse',\n",
    " 'max_depth': None,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 10,\n",
    " 'n_estimators': 200,\n",
    " 'n_jobs': 6}\n",
    "rf_list_15stations = []\n",
    "for ytrain in tqdm(ytrain_list):\n",
    "    rf = RandomForestRegressor(**p, verbose=0)\n",
    "    rf.fit(Xtrain,ytrain)\n",
    "    rf_list_15stations.append(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 1093/1093 [00:09<00:00, 118.02it/s]\n",
      "100%|██████████| 68/68 [00:14<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6100480166\n",
      "29.609964402\n",
      "876.749991889\n",
      "12.6160008791\n"
     ]
    }
   ],
   "source": [
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2017-12-31 23:45:00'\n",
    "df_Xy_pred = df_Xy[start_datetime:end_datetime]\n",
    "Xpred, ypred_list, Xnames, days_pred = create_xy_dataset(df_Xy_pred, time_series, features_exogenous, features_context)\n",
    "\n",
    "pred_list = []\n",
    "for rf in tqdm(rf_list_15stations):\n",
    "    pred_list.append(rf.predict(Xpred))\n",
    "pred_list = np.array(pred_list)\n",
    "\n",
    "print(mape_at(ypred_list, pred_list))\n",
    "print(rmse(ypred_list, pred_list))\n",
    "print(mse(ypred_list, pred_list))\n",
    "print(mae(ypred_list, pred_list))\n",
    "\n",
    "df = pred_list_to_dataframe(pred_list, time_series, days_pred)\n",
    "\n",
    "df.to_csv('/home/toque/data2/forecast/model/rf_inverted/prediction/rf_inverted_15stationsexo_contextcal_withoutoptim6min/2015-01-01_2016-12-31.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 731/731 [00:06<00:00, 116.31it/s]\n",
      "100%|██████████| 68/68 [01:42<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "features_exogenous = [ '12-start_event',\n",
    "  '13-start_event', '15-start_event', '16-start_event',\n",
    "  '23-start_event', '24-start_event', '31-start_event',\n",
    "  '32-start_event', '45-start_event', '61-start_event', '12-end_event', '13-end_event', '15-end_event',\n",
    "  '16-end_event', '23-end_event', '24-end_event', '31-end_event', '32-end_event', '45-end_event',\n",
    "  '61-end_event', '12-period_event', '13-period_event', '15-period_event',\n",
    "  '16-period_event', '23-period_event', '24-period_event',\n",
    "  '31-period_event', '32-period_event', '45-period_event', '61-period_event']\n",
    "\n",
    "\n",
    "df_Xy = df_observation.set_index('Datetime').join([df_context.set_index('Datetime'), df_exogenous.set_index('Datetime')])\n",
    "\n",
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2016-12-31 23:45:00'\n",
    "df_Xy_train = df_Xy[start_datetime:end_datetime]\n",
    "Xtrain, ytrain_list, Xnames, days = create_xy_dataset(df_Xy_train, time_series, features_exogenous, features_context)\n",
    "\n",
    "rf_list_10stations = []\n",
    "for ytrain in tqdm(ytrain_list):\n",
    "    rf = RandomForestRegressor(**p, verbose=0)\n",
    "    rf.fit(Xtrain,ytrain)\n",
    "    rf_list_10stations.append(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 1093/1093 [00:09<00:00, 117.12it/s]\n"
     ]
    }
   ],
   "source": [
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2017-12-31 23:45:00'\n",
    "df_Xy_pred = df_Xy[start_datetime:end_datetime]\n",
    "Xpred, ypred_list, Xnames, days_pred = create_xy_dataset(df_Xy_pred, time_series, features_exogenous, features_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:14<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6349150232\n",
      "29.6660906757\n",
      "880.076935981\n",
      "12.6231035849\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for rf in tqdm(rf_list_10stations):\n",
    "    pred_list.append(rf.predict(Xpred))\n",
    "pred_list = np.array(pred_list)\n",
    "\n",
    "print(mape_at(ypred_list, pred_list))\n",
    "print(rmse(ypred_list, pred_list))\n",
    "print(mse(ypred_list, pred_list))\n",
    "print(mae(ypred_list, pred_list))\n",
    "\n",
    "df = pred_list_to_dataframe(pred_list, time_series, days_pred)\n",
    "\n",
    "df.to_csv('/home/toque/data2/forecast/model/rf_inverted/prediction/rf_inverted_10stationsexo_contextcal_withoutoptim6min/2015-01-01_2016-12-31.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 731/731 [00:06<00:00, 115.23it/s]\n",
      "100%|██████████| 68/68 [00:22<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "features_exogenous = []\n",
    "\n",
    "\n",
    "df_Xy = df_observation.set_index('Datetime').join([df_context.set_index('Datetime'), df_exogenous.set_index('Datetime')])\n",
    "\n",
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2016-12-31 23:45:00'\n",
    "df_Xy_train = df_Xy[start_datetime:end_datetime]\n",
    "Xtrain, ytrain_list, Xnames, days = create_xy_dataset(df_Xy_train, time_series, features_exogenous, features_context)\n",
    "\n",
    "rf_list_0stations = []\n",
    "for ytrain in tqdm(ytrain_list):\n",
    "    rf = RandomForestRegressor(**p, verbose=0)\n",
    "    rf.fit(Xtrain,ytrain)\n",
    "    rf_list_0stations.append(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 1093/1093 [00:09<00:00, 115.44it/s]\n"
     ]
    }
   ],
   "source": [
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2017-12-31 23:45:00'\n",
    "df_Xy_pred = df_Xy[start_datetime:end_datetime]\n",
    "Xpred, ypred_list, Xnames, days_pred = create_xy_dataset(df_Xy_pred, time_series, features_exogenous, features_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:13<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.0824746327\n",
      "34.2750358755\n",
      "1174.77808426\n",
      "13.6830421636\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for rf in tqdm(rf_list_0stations):\n",
    "    pred_list.append(rf.predict(Xpred))\n",
    "pred_list = np.array(pred_list)\n",
    "\n",
    "print(mape_at(ypred_list, pred_list))\n",
    "print(rmse(ypred_list, pred_list))\n",
    "print(mse(ypred_list, pred_list))\n",
    "print(mae(ypred_list, pred_list))\n",
    "\n",
    "df = pred_list_to_dataframe(pred_list, time_series, days_pred)\n",
    "\n",
    "df.to_csv('/home/toque/data2/forecast/model/rf_inverted/prediction/rf_inverted_0stationsexo_contextcal_withoutoptim6min/2015-01-01_2016-12-31.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meteo day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 731/731 [00:06<00:00, 106.66it/s]\n",
      "100%|██████████| 68/68 [00:31<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "features_context = ['Day_id', 'Mois_id','vac_noel_quebec', 'day_off_quebec', '24DEC', '31DEC',\n",
    "                    'renov_beaubien', 'vac_udem1', 'vac_udem2', 'Temperature_min_celcius', 'Temperature_max_celcius',\n",
    "                    'Humidex_celcius', 'Windchill_celcius', 'Probability', 'Water_height_mm', 'Snow_height_cm']\n",
    "features_exogenous = []\n",
    "\n",
    "df_Xy = df_observation.set_index('Datetime').join([df_context.set_index('Datetime'), df_exogenous.set_index('Datetime')])\n",
    "\n",
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2016-12-31 23:45:00'\n",
    "df_Xy_train = df_Xy[start_datetime:end_datetime]\n",
    "Xtrain, ytrain_list, Xnames, days = create_xy_dataset(df_Xy_train, time_series, features_exogenous, features_context)\n",
    "\n",
    "rf_list_meteo = []\n",
    "for ytrain in tqdm(ytrain_list):\n",
    "    rf = RandomForestRegressor(**p, verbose=0)\n",
    "    rf.fit(Xtrain,ytrain)\n",
    "    rf_list_meteo.append(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 1027/1027 [00:09<00:00, 104.33it/s]\n"
     ]
    }
   ],
   "source": [
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2017-12-31 23:45:00'\n",
    "df_Xy_pred = df_Xy[start_datetime:end_datetime]\n",
    "Xpred, ypred_list, Xnames, days_pred = create_xy_dataset(df_Xy_pred, time_series, features_exogenous, features_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:14<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.2560931804\n",
      "31.0098156654\n",
      "961.608667603\n",
      "12.7690460991\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for rf in tqdm(rf_list_meteo):\n",
    "    pred_list.append(rf.predict(Xpred))\n",
    "pred_list = np.array(pred_list)\n",
    "\n",
    "print(mape_at(ypred_list, pred_list))\n",
    "print(rmse(ypred_list, pred_list))\n",
    "print(mse(ypred_list, pred_list))\n",
    "print(mae(ypred_list, pred_list))\n",
    "\n",
    "df = pred_list_to_dataframe(pred_list, time_series, days_pred)\n",
    "\n",
    "df.to_csv('/home/toque/data2/forecast/model/rf_inverted/prediction/rf_inverted_0stationsexo_contextcalmeteoday_withoutoptim6min/2015-01-01_2016-12-31.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meteo day + event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 731/731 [00:06<00:00, 105.55it/s]\n",
      "100%|██████████| 68/68 [02:17<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "features_context = ['Day_id', 'Mois_id','vac_noel_quebec', 'day_off_quebec', '24DEC', '31DEC',\n",
    "                    'renov_beaubien', 'vac_udem1', 'vac_udem2', 'Temperature_min_celcius', 'Temperature_max_celcius',\n",
    "                    'Humidex_celcius', 'Windchill_celcius', 'Probability', 'Water_height_mm', 'Snow_height_cm']\n",
    "features_exogenous = ['5-end_event', '11-end_event', '12-end_event', '13-end_event',\n",
    "       '15-end_event', '16-end_event', '23-end_event', '24-end_event',\n",
    "       '31-end_event', '32-end_event', '35-end_event', '43-end_event',\n",
    "       '45-end_event', '61-end_event', '68-end_event', '5-start_event',\n",
    "       '11-start_event', '12-start_event', '13-start_event',\n",
    "       '15-start_event', '16-start_event', '23-start_event',\n",
    "       '24-start_event', '31-start_event', '32-start_event',\n",
    "       '35-start_event', '43-start_event', '45-start_event',\n",
    "       '61-start_event', '68-start_event', '5-period_event',\n",
    "       '11-period_event', '12-period_event', '13-period_event',\n",
    "       '15-period_event', '16-period_event', '23-period_event',\n",
    "       '24-period_event', '31-period_event', '32-period_event',\n",
    "       '35-period_event', '43-period_event', '45-period_event',\n",
    "       '61-period_event', '68-period_event']\n",
    "\n",
    "df_Xy = df_observation.set_index('Datetime').join([df_context.set_index('Datetime'), df_exogenous.set_index('Datetime')])\n",
    "\n",
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2016-12-31 23:45:00'\n",
    "df_Xy_train = df_Xy[start_datetime:end_datetime]\n",
    "Xtrain, ytrain_list, Xnames, days = create_xy_dataset(df_Xy_train, time_series, features_exogenous, features_context)\n",
    "\n",
    "rf_list_meteo15stations = []\n",
    "for ytrain in tqdm(ytrain_list):\n",
    "    rf = RandomForestRegressor(**p, verbose=0)\n",
    "    rf.fit(Xtrain,ytrain)\n",
    "    rf_list_meteo15stations.append(rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Days loop: 100%|██████████| 1027/1027 [00:09<00:00, 107.15it/s]\n"
     ]
    }
   ],
   "source": [
    "start_datetime, end_datetime = '2015-01-01 00:00:00', '2017-12-31 23:45:00'\n",
    "df_Xy_pred = df_Xy[start_datetime:end_datetime]\n",
    "Xpred, ypred_list, Xnames, days_pred = create_xy_dataset(df_Xy_pred, time_series, features_exogenous, features_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:14<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.2203841311\n",
      "28.0771396727\n",
      "788.3257722\n",
      "12.1563958957\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for rf in tqdm(rf_list_meteo15stations):\n",
    "    pred_list.append(rf.predict(Xpred))\n",
    "pred_list = np.array(pred_list)\n",
    "\n",
    "print(mape_at(ypred_list, pred_list))\n",
    "print(rmse(ypred_list, pred_list))\n",
    "print(mse(ypred_list, pred_list))\n",
    "print(mae(ypred_list, pred_list))\n",
    "\n",
    "df = pred_list_to_dataframe(pred_list, time_series, days_pred)\n",
    "\n",
    "df.to_csv('/home/toque/data2/forecast/model/rf_inverted/prediction/rf_inverted_15stationsexo_contextcalmeteoday_withoutoptim6min/2015-01-01_2016-12-31.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn with best params/features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction -> csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_list_to_dataframe(pred_list, time_series, days):\n",
    "    data = [j for i in [build_timestamp_list(d+' 00:00:00', d+ ' 23:45:00') for d in days] for j in i]\n",
    "    df = pd.DataFrame(data=data, columns=['Datetime'])\n",
    "    for ix, ts in enumerate(time_series):\n",
    "        df[ts] = pred_list[ix].reshape(pred_list[ix].shape[0]*pred_list[ix].shape[1])\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 - env",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
