{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from model.ha.ha_model import Ha_model\n",
    "from utils.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "observation_data_path = ['../data/observation_file_2017-01-01_2017-06-30_included_test.csv']\n",
    "exogenous_data_path = ['../data/date_file_2013_2018_included_test.csv']\n",
    "features_list = [['Day_id', 'Month_id', 'School_holidays_france_zoneC', 'Extra_day_off_france',\n",
    "                  'Holidays_france', 'hour_minute_second_numerical'], ['hour_minute_second_numerical']]\n",
    "time_series = ['71634', '71650', '71442', '71654', '71743', '71328',\n",
    "               '71305', '71517', '71284', '415852', '71404', '71298', '73630',\n",
    "               '71318', '71348', '71379', '71647', '71663', '71673', '71485',\n",
    "               '71222', '71297', '71347', '71100', '71133', '71217', '73696',\n",
    "               '73689', '71407', '73616', '70537', '70636', '70375', '71351',\n",
    "               '71977', '70452', '72031', '72013', '70645', '71253', '71363',\n",
    "               '70596', '72430', '71201', '72460', '70488', '71076', '70604',\n",
    "               '73695', '70143', '70248', '71001', '73615']\n",
    "\n",
    "model_name = 'rf_model_test'\n",
    "start_date = '2017-01-01 00:00:00'\n",
    "end_date = '2017-01-05 00:00:00'\n",
    "path_to_save = '../data/model/test/rf/'\n",
    "param_kfold = {'n_splits': 2, 'shuffle': True, 'random_state': 0}\n",
    "param_grid = {'n_estimators': [1], 'max_features': ['auto'], 'max_depth': [None], 'min_samples_split': [5],\n",
    "              'min_samples_leaf': [5], 'n_jobs': [6], 'criterion': ['mse']}\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "scaler_choice = \"standard\"\n",
    "\n",
    "#path_directory_to_save = path_to_save + model_name + '/'\n",
    "\n",
    "df_Xy = read_csv_list(observation_data_path).set_index('Datetime').join(\n",
    "    read_csv_list(exogenous_data_path).set_index('Datetime'))[start_date:end_date]\n",
    "\n",
    "X_list = [df_Xy[features].values for features in features_list]\n",
    "y = df_Xy[time_series].values\n",
    "\n",
    "my_model = Rf_model(model_name, start_date, end_date, features_list, time_series, observation_data_path,\n",
    "                    exogenous_data_path, scaler_choice)\n",
    "grid_search_dict = my_model.optimize(X_list, y, param_grid, param_kfold, scoring)\n",
    "\n",
    "best_conf = [(features, grid_search_dict[tuple(features)].best_params_,\n",
    "              grid_search_dict[tuple(features)].best_score_) for features in list(grid_search_dict.keys())]\n",
    "best_conf.sort(key=lambda x: x[2])\n",
    "features = list(best_conf[-1][0])\n",
    "best_params = best_conf[-1][1]\n",
    "assert( best_params['n_estimators']==1)\n",
    "assert( best_params['max_features']=='auto')\n",
    "assert( best_params['min_samples_leaf']==5)\n",
    "assert( best_params['n_jobs']==6)\n",
    "assert( best_params['min_samples_split']==5)\n",
    "assert( best_params['criterion']=='mse')\n",
    "assert( best_params['max_depth']==None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.07, 'Extra_day_off_france': 0.0, 'Day_id': 15.68, 'hour_minute_second_numerical': 84.15, 'School_holidays_france_zoneC': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.07, 'Extra_day_off_france': 0.0, 'Day_id': 16.27, 'hour_minute_second_numerical': 83.56, 'School_holidays_france_zoneC': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.06, 'Extra_day_off_france': 0.0, 'Day_id': 16.04, 'hour_minute_second_numerical': 83.78, 'School_holidays_france_zoneC': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.08, 'Extra_day_off_france': 0.0, 'Day_id': 15.93, 'hour_minute_second_numerical': 83.88, 'School_holidays_france_zoneC': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.06, 'Extra_day_off_france': 0.0, 'Day_id': 16.0, 'hour_minute_second_numerical': 83.84, 'School_holidays_france_zoneC': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.06, 'Extra_day_off_france': 0.0, 'Day_id': 15.74, 'hour_minute_second_numerical': 84.09, 'School_holidays_france_zoneC': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.08, 'Extra_day_off_france': 0.0, 'Day_id': 15.83, 'hour_minute_second_numerical': 83.99, 'School_holidays_france_zoneC': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.07, 'Extra_day_off_france': 0.0, 'Day_id': 15.72, 'hour_minute_second_numerical': 84.09, 'School_holidays_france_zoneC': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.06, 'Extra_day_off_france': 0.0, 'Day_id': 15.83, 'hour_minute_second_numerical': 84.0, 'School_holidays_france_zoneC': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Month_id': 0.0, 'Holidays_france': 0.07, 'Extra_day_off_france': 0.0, 'Day_id': 15.84, 'hour_minute_second_numerical': 83.91, 'School_holidays_france_zoneC': 0.18}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    observation_data_path = ['../data/observation_file_2017-01-01_2017-06-30_included_test.csv']\n",
    "    exogenous_data_path = ['../data/date_file_2013_2018_included_test.csv']\n",
    "    features = ['Day_id', 'Month_id', 'School_holidays_france_zoneC', 'Extra_day_off_france',\n",
    "                'Holidays_france', 'hour_minute_second_numerical']\n",
    "    time_series = ['71634', '71650', '71442', '71654', '71743', '71328',\n",
    "                   '71305', '71517', '71284', '415852', '71404', '71298', '73630',\n",
    "                   '71318', '71348', '71379', '71647', '71663', '71673', '71485',\n",
    "                   '71222', '71297', '71347', '71100', '71133', '71217', '73696',\n",
    "                   '73689', '71407', '73616', '70537', '70636', '70375', '71351',\n",
    "                   '71977', '70452', '72031', '72013', '70645', '71253', '71363',\n",
    "                   '70596', '72430', '71201', '72460', '70488', '71076', '70604',\n",
    "                   '73695', '70143', '70248', '71001', '73615']\n",
    "\n",
    "    model_name = 'rf_model_test'\n",
    "    start_date = '2017-01-01 00:00:00'\n",
    "    end_date = '2017-01-31 00:00:00'\n",
    "    path_to_save = '../data/model/test/rf/'\n",
    "    scaler_choice = 'standard'\n",
    "    best_params = {'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 3,\n",
    "                   'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': 6}\n",
    "\n",
    "    df_observation = read_csv_list(observation_data_path)\n",
    "    df_exogenous = read_csv_list(exogenous_data_path)\n",
    "\n",
    "    df_Xy = df_observation.set_index('Datetime').join(df_exogenous.set_index(\"Datetime\"))[start_date:end_date]\n",
    "    X = df_Xy[features].values\n",
    "    y = df_Xy[time_series].values\n",
    "\n",
    "\n",
    "    my_model = Rf_model(model_name, start_date, end_date, [features], time_series, observation_data_path,\n",
    "                        exogenous_data_path, scaler_choice)\n",
    "    my_model.infos['features'] = features\n",
    "    my_model.infos['best_params'] = best_params\n",
    "\n",
    "    rf = my_model.fit(X, y, my_model.infos['best_params'])\n",
    "\n",
    "    feature_importances = dict(zip(features, np.round(rf.feature_importances_ * 100, 2).tolist()))\n",
    "    my_model.infos[\"feature_importances\"] = feature_importances\n",
    "\n",
    "    assert(my_model.infos['name'] ==  model_name)\n",
    "    assert(my_model.infos['features'] ==  features)\n",
    "    assert(my_model.infos['time_series'] ==  time_series)\n",
    "    assert(my_model.infos['start_date'] ==  start_date)\n",
    "    assert(my_model.infos['end_date'] ==  end_date)\n",
    "    assert(my_model.infos['exogenous_data_path'] ==  exogenous_data_path)\n",
    "    assert(my_model.infos['observation_data_path'] ==  observation_data_path)\n",
    "    assert(my_model.infos['best_params'] ==  best_params)\n",
    "    assert(my_model.infos['feature_importances'] ==  feature_importances)\n",
    "    print (feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4344, 53)\n",
      "(4344, 53)\n",
      "(53,)\n",
      "28.2373201132 437.337070781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "observation_data_path = ['../data/observation_file_2017-01-01_2017-06-30_included_test.csv']\n",
    "exogenous_data_path = ['../data/date_file_2013_2018_included_test.csv']\n",
    "features = ['Day_id', 'Month_id', 'School_holidays_france_zoneC', 'Extra_day_off_france',\n",
    "            'Holidays_france', 'hour_minute_second_numerical']\n",
    "time_series = ['71634', '71650', '71442', '71654', '71743', '71328',\n",
    "               '71305', '71517', '71284', '415852', '71404', '71298', '73630',\n",
    "               '71318', '71348', '71379', '71647', '71663', '71673', '71485',\n",
    "               '71222', '71297', '71347', '71100', '71133', '71217', '73696',\n",
    "               '73689', '71407', '73616', '70537', '70636', '70375', '71351',\n",
    "               '71977', '70452', '72031', '72013', '70645', '71253', '71363',\n",
    "               '70596', '72430', '71201', '72460', '70488', '71076', '70604',\n",
    "               '73695', '70143', '70248', '71001', '73615']\n",
    "\n",
    "model_name = 'rf_model_test'\n",
    "start_date = '2017-01-01 00:00:00'\n",
    "end_date = '2017-12-31 00:00:00'\n",
    "path_to_save = '../data/model/test/rf/'\n",
    "scaler_choice = 'standard'\n",
    "best_params = {'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 3,\n",
    "               'min_samples_split': 5, 'n_estimators': 100, 'n_jobs': 6}\n",
    "\n",
    "df_observation = read_csv_list(observation_data_path)\n",
    "df_exogenous = read_csv_list(exogenous_data_path)\n",
    "\n",
    "df_Xy = df_observation.set_index('Datetime').join(df_exogenous.set_index(\"Datetime\"))[start_date:end_date]\n",
    "X = df_Xy[features].values\n",
    "y = df_Xy[time_series].values\n",
    "\n",
    "my_model = Rf_model(model_name, start_date, end_date, [features], time_series, observation_data_path,\n",
    "                    exogenous_data_path, scaler_choice)\n",
    "my_model.infos['features'] = features\n",
    "my_model.infos['best_params'] = best_params\n",
    "\n",
    "rf = my_model.fit(X, y, my_model.infos['best_params'])\n",
    "\n",
    "feature_importances = dict(zip(features, np.round(rf.feature_importances_ * 100, 2).tolist()))\n",
    "my_model.infos[\"feature_importances\"] = feature_importances\n",
    "\n",
    "\n",
    "X = df_Xy[my_model.infos['features']].values\n",
    "obs = np.around(df_Xy[time_series][start_date:end_date].values, decimals=2)\n",
    "pred = my_model.predict(rf, X)\n",
    "pred_mean = np.around(df_Xy[time_series][start_date:end_date].values.mean(axis=0), decimals=2)\n",
    "\n",
    "assert(np.abs(pred-obs).mean()<np.abs(pred_mean-obs).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  471.20107235,   283.09032627,   650.92547703,   568.6844622 ,\n",
       "        1118.22422162,   476.9383416 ,   270.39956395,  5904.97384939,\n",
       "         176.9107872 ,   912.70058285,   514.95485748,   400.57844309,\n",
       "         174.24660566,   787.62918596,   259.00252224,   977.25324949,\n",
       "         593.25532205,   731.56095532,  1237.70067127,   953.96042086,\n",
       "         487.08857873,   568.8620866 ,  1317.16638919,   314.91609894,\n",
       "         252.70662581,   122.71399033,   587.91614105,   546.1985232 ,\n",
       "         223.49385803,   223.71725808,   147.40170686,   178.52578142,\n",
       "         244.63717555,   282.70121317,   227.38505785,   422.43652495,\n",
       "         277.21809597,   575.10599701,   192.56151105,   109.49925147,\n",
       "         316.21384761,   214.84150329,   347.49604604,   146.44409512,\n",
       "         736.76453874,   299.92767219,   329.84403027,   277.26230442,\n",
       "         399.73900953,   662.39369385,   220.52883508,   322.42134093,\n",
       "         175.04278375])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dict_pred_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-5152394d69fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mobs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_observation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Datetime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2017-01-01 00:00:00'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dict_pred_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mobs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_observation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Datetime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2017-01-01 01:00:00'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mres2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dict_pred_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dict_pred_mean'"
     ]
    }
   ],
   "source": [
    "obs1 = np.around(df_observation.set_index('Datetime').loc['2017-01-01 00:00:00'].values, decimals=2) \n",
    "res1 = np.around(my_model.infos['dict_pred_mean'][(6,1,1,0,1,0)].astype(float), decimals=2)\n",
    "obs2 = np.around(df_observation.set_index('Datetime').loc['2017-01-01 01:00:00'].values, decimals=2) \n",
    "res2 = np.around(my_model.infos['dict_pred_mean'][(6,1,1,0,1,1)].astype(float), decimals=2)\n",
    "\n",
    "print((obs1!=res1).sum() == 0)\n",
    "print((obs2!=res2).sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.4593, 7.807, 10.7536, 22.8844, 146.96439999999996, 124.2087,\n",
       "       24.178, 109.446, 10.6672, 80.2373, 9.8027, 90.0448, 16.8435, 57.816,\n",
       "       8.630400000000002, 68.0279, 17.4, 28.216000000000005, 77.0412,\n",
       "       15.7896, 0.5281999999999999, 43.9401, 153.6652, 18.9126, 38.7772,\n",
       "       15.806400000000002, 14.336199999999998, 13.468800000000002,\n",
       "       12.275200000000002, 10.2363, 4.7817, 9.7092, 5.659200000000001,\n",
       "       18.1482, 10.251, 0.0, 10.8222, 27.966, 9.5118, 11.6332, 12.6984,\n",
       "       12.0736, 32.7104, 10.2176, 39.0145, 7.3299, 22.1378, 9.0321,\n",
       "       11.7978, 14.704199999999998, 4.83, 15.6462, 3.8402], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.infos['dict_pred_mean'][(6,1,1,0,1,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dict_pred_mean', 'dict_pred_median', 'features', 'exogenous_data_path', 'start_date', 'observation_data_path', 'name', 'time_series', 'end_date'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.infos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Day_id', 'Month_id', 'School_holidays_france_zoneC', 'Extra_day_off_france',\n",
    "                    'Holidays_france', 'hour_minute_second_numerical']\n",
    "time_series = ['71634', '71650', '71442', '71654', '71743', '71328',\n",
    "               '71305', '71517', '71284', '415852', '71404', '71298', '73630',\n",
    "               '71318', '71348', '71379', '71647', '71663', '71673', '71485',\n",
    "               '71222', '71297', '71347', '71100', '71133', '71217', '73696',\n",
    "               '73689', '71407', '73616', '70537', '70636', '70375', '71351',\n",
    "               '71977', '70452', '72031', '72013', '70645', '71253', '71363',\n",
    "               '70596', '72430', '71201', '72460', '70488', '71076', '70604',\n",
    "               '73695', '70143', '70248', '71001', '73615']\n",
    "\n",
    "model_name = 'ha_model_test'\n",
    "start_date = '2017-01-01 00:00:00'\n",
    "end_date = '2017-01-01 01:00:00'\n",
    "path_to_save = '../data/model/ha/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/date_file_2013_2018_included_test.csv']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.infos['features'] == features\n",
    "my_model.infos['time_series'] == time_series\n",
    "my_model.infos['start_date'] == start_date\n",
    "my_model.infos['end_date'] == end_date\n",
    "my_model.infos['exogenous_data_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>71634</th>\n",
       "      <th>71650</th>\n",
       "      <th>71442</th>\n",
       "      <th>71654</th>\n",
       "      <th>71743</th>\n",
       "      <th>71328</th>\n",
       "      <th>71305</th>\n",
       "      <th>71517</th>\n",
       "      <th>71284</th>\n",
       "      <th>415852</th>\n",
       "      <th>...</th>\n",
       "      <th>71201</th>\n",
       "      <th>72460</th>\n",
       "      <th>70488</th>\n",
       "      <th>71076</th>\n",
       "      <th>70604</th>\n",
       "      <th>73695</th>\n",
       "      <th>70143</th>\n",
       "      <th>70248</th>\n",
       "      <th>71001</th>\n",
       "      <th>73615</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>22.4593</td>\n",
       "      <td>7.807</td>\n",
       "      <td>10.7536</td>\n",
       "      <td>22.8844</td>\n",
       "      <td>146.9644</td>\n",
       "      <td>124.2087</td>\n",
       "      <td>24.1780</td>\n",
       "      <td>109.4460</td>\n",
       "      <td>10.6672</td>\n",
       "      <td>80.2373</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2176</td>\n",
       "      <td>39.0145</td>\n",
       "      <td>7.3299</td>\n",
       "      <td>22.1378</td>\n",
       "      <td>9.0321</td>\n",
       "      <td>11.7978</td>\n",
       "      <td>14.7042</td>\n",
       "      <td>4.830</td>\n",
       "      <td>15.6462</td>\n",
       "      <td>3.8402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>1.8891</td>\n",
       "      <td>1.477</td>\n",
       "      <td>2.0680</td>\n",
       "      <td>3.2692</td>\n",
       "      <td>21.7932</td>\n",
       "      <td>9.6558</td>\n",
       "      <td>2.4178</td>\n",
       "      <td>12.3395</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>8.8660</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4800</td>\n",
       "      <td>3.2970</td>\n",
       "      <td>1.3830</td>\n",
       "      <td>2.0267</td>\n",
       "      <td>1.0626</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>1.7505</td>\n",
       "      <td>1.155</td>\n",
       "      <td>2.4612</td>\n",
       "      <td>0.6330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       71634  71650    71442    71654     71743     71328  \\\n",
       "Datetime                                                                    \n",
       "2017-01-01 00:00:00  22.4593  7.807  10.7536  22.8844  146.9644  124.2087   \n",
       "2017-01-01 01:00:00   1.8891  1.477   2.0680   3.2692   21.7932    9.6558   \n",
       "\n",
       "                       71305     71517    71284   415852   ...      71201  \\\n",
       "Datetime                                                   ...              \n",
       "2017-01-01 00:00:00  24.1780  109.4460  10.6672  80.2373   ...    10.2176   \n",
       "2017-01-01 01:00:00   2.4178   12.3395   0.9040   8.8660   ...     2.4800   \n",
       "\n",
       "                       72460   70488    71076   70604    73695    70143  \\\n",
       "Datetime                                                                  \n",
       "2017-01-01 00:00:00  39.0145  7.3299  22.1378  9.0321  11.7978  14.7042   \n",
       "2017-01-01 01:00:00   3.2970  1.3830   2.0267  1.0626   0.8427   1.7505   \n",
       "\n",
       "                     70248    71001   73615  \n",
       "Datetime                                     \n",
       "2017-01-01 00:00:00  4.830  15.6462  3.8402  \n",
       "2017-01-01 01:00:00  1.155   2.4612  0.6330  \n",
       "\n",
       "[2 rows x 53 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_observation['2017-01-01 00:00:00':'2017-01-01 01:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_id_name = dict(pd.read_csv('../data/station_information.csv')[['ID_REFA_LDA','NOM_GARE']].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LA D?FENSE-GRANDE ARCHE'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_id_name[71517]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 11008.67it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 12985.46it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ha_model_test'\n",
    "path_to_save = '../data/model/test/ha/'\n",
    "load_model = load_pickle(path_to_save + model_name + '.pkl')\n",
    "exogenous_data_path = load_model.infos['exogenous_data_path']\n",
    "list_date = ['2017-01-01 00:00:00', '2017-01-01 01:00:00']\n",
    "\n",
    "X = read_csv_list(exogenous_data_path).set_index('Datetime').ix[list_date][load_model.infos['features']].values\n",
    "pred_mean = load_model.predict(X, choice='mean')\n",
    "pred_median = load_model.predict(X, choice='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  22.4593,    7.807 ,   10.7536,   22.8844,  146.9644,  124.2087,\n",
       "         24.178 ,  109.446 ,   10.6672,   80.2373,    9.8027,   90.0448,\n",
       "         16.8435,   57.816 ,    8.6304,   68.0279,   17.4   ,   28.216 ,\n",
       "         77.0412,   15.7896,    0.5282,   43.9401,  153.6652,   18.9126,\n",
       "         38.7772,   15.8064,   14.3362,   13.4688,   12.2752,   10.2363,\n",
       "          4.7817,    9.7092,    5.6592,   18.1482,   10.251 ,    0.    ,\n",
       "         10.8222,   27.966 ,    9.5118,   11.6332,   12.6984,   12.0736,\n",
       "         32.7104,   10.2176,   39.0145,    7.3299,   22.1378,    9.0321,\n",
       "         11.7978,   14.7042,    4.83  ,   15.6462,    3.8402])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from model.rf.rf_model import Rf_model\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.7s finished\n",
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.7s finished\n",
      "/opt/conda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "observation_data_path = ['../data/observation_file_2017-01-01_2017-06-30_included_test.csv']\n",
    "exogenous_data_path = ['../data/date_file_2013_2018_included_test.csv']\n",
    "features_list = [['Day_id', 'Month_id', 'School_holidays_france_zoneC', 'Extra_day_off_france',\n",
    "                  'Holidays_france', 'hour_minute_second_numerical'], ['hour_minute_second_numerical']]\n",
    "time_series = ['71634', '71650', '71442', '71654', '71743', '71328',\n",
    "               '71305', '71517', '71284', '415852', '71404', '71298', '73630',\n",
    "               '71318', '71348', '71379', '71647', '71663', '71673', '71485',\n",
    "               '71222', '71297', '71347', '71100', '71133', '71217', '73696',\n",
    "               '73689', '71407', '73616', '70537', '70636', '70375', '71351',\n",
    "               '71977', '70452', '72031', '72013', '70645', '71253', '71363',\n",
    "               '70596', '72430', '71201', '72460', '70488', '71076', '70604',\n",
    "               '73695', '70143', '70248', '71001', '73615']\n",
    "\n",
    "model_name = 'rf_model_test'\n",
    "start_date = '2017-01-01 00:00:00'\n",
    "end_date = '2017-01-31 00:00:00'\n",
    "path_to_save = '../data/model/test/rf/'\n",
    "param_kfold = {'n_splits': 2, 'shuffle': True, 'random_state': 0}\n",
    "param_grid = {'n_estimators': [10, 30], 'max_features': ['auto'], 'max_depth': [None], 'min_samples_split': [5],\n",
    "              'min_samples_leaf': [3, 5], 'n_jobs': [6], 'criterion': ['mse']}\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "scaler_choice = \"standard\"\n",
    "\n",
    "path_directory_to_save = path_to_save + model_name + '/'\n",
    "\n",
    "df_Xy = read_csv_list(observation_data_path).set_index('Datetime').join(\n",
    "    read_csv_list(exogenous_data_path).set_index('Datetime'))[start_date:end_date]\n",
    "\n",
    "X_list = [df_Xy[features].values for features in features_list]\n",
    "y = df_Xy[time_series].values\n",
    "\n",
    "my_model = Rf_model(model_name, start_date, end_date, features_list, time_series, observation_data_path,\n",
    "                    exogenous_data_path, scaler_choice)\n",
    "\n",
    "grid_search_dict = my_model.optimize(X_list, y, param_grid, param_kfold, scoring)\n",
    "\n",
    "best_conf = [(features, grid_search_dict[tuple(features)].best_params_,\n",
    "                      grid_search_dict[tuple(features)].best_score_) for features in list(grid_search_dict.keys())]\n",
    "best_conf.sort(key=lambda x: x[2])\n",
    "features = list(best_conf[-1][0])\n",
    "best_params = best_conf[-1][1]\n",
    "my_model.infos['features'] = features\n",
    "my_model.infos['best_params'] = best_params\n",
    "\n",
    "\n",
    "\n",
    "df_observation = read_csv_list(observation_data_path)\n",
    "df_exogenous = read_csv_list(exogenous_data_path)\n",
    "\n",
    "df_Xy = df_observation.set_index('Datetime').join(df_exogenous.set_index(\"Datetime\"))[start_date:end_date]\n",
    "X = df_Xy[features].values\n",
    "y = df_Xy[time_series].values\n",
    "\n",
    "rf = my_model.fit(X, y, my_model.infos['best_params'])\n",
    "\n",
    "feature_importances = dict(zip(features, np.round(rf.feature_importances_ * 100, 2).tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-b15a1d76ead5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mobservation_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'../data/observation_file_2017-01-01_2017-06-30_included_test.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdf_observation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexogenous_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Datetime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpred_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpred_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'median'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'features'"
     ]
    }
   ],
   "source": [
    "model_name = 'rf_model_test'\n",
    "path_to_save = '../data/model/test/rf/'\n",
    "load_model = load_pickle(path_to_save + model_name + '/rf_model_test.pkl')\n",
    "exogenous_data_path = load_model.infos['exogenous_data_path']\n",
    "list_date = ['2017-01-01 00:00:00', '2017-01-01 01:00:00']\n",
    "\n",
    "\n",
    "observation_data_path = ['../data/observation_file_2017-01-01_2017-06-30_included_test.csv']\n",
    "df_observation = read_csv_list(observation_data_path)\n",
    "X = read_csv_list(exogenous_data_path).set_index('Datetime').ix[list_date][load_model.infos['features']].values\n",
    "pred_mean = load_model.predict(X, choice='mean')\n",
    "pred_median = load_model.predict(X, choice='median')\n",
    "\n",
    "res1 = np.around(pred_mean[0], decimals=2)\n",
    "res2 = np.around(pred_mean[1], decimals=2)\n",
    "res1_ = np.around(pred_median[0], decimals=2)\n",
    "res2_ = np.around(pred_median[1], decimals=2)\n",
    "obs1 = np.around(df_observation.set_index('Datetime').loc['2017-01-01 00:00:00'].values, decimals=2)\n",
    "obs2 = np.around(df_observation.set_index('Datetime').loc['2017-01-01 01:00:00'].values, decimals=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end_date': '2017-01-31 00:00:00',\n",
       " 'exogenous_data_path': ['../data/date_file_2013_2018_included_test.csv'],\n",
       " 'features_list': [['Day_id',\n",
       "   'Month_id',\n",
       "   'School_holidays_france_zoneC',\n",
       "   'Extra_day_off_france',\n",
       "   'Holidays_france',\n",
       "   'hour_minute_second_numerical'],\n",
       "  ['hour_minute_second_numerical']],\n",
       " 'name': 'rf_model_test',\n",
       " 'observation_data_path': ['../data/observation_file_2017-01-01_2017-06-30_included_test.csv'],\n",
       " 'scaler_choice': 'standard',\n",
       " 'start_date': '2017-01-01 00:00:00',\n",
       " 'time_series': ['71634',\n",
       "  '71650',\n",
       "  '71442',\n",
       "  '71654',\n",
       "  '71743',\n",
       "  '71328',\n",
       "  '71305',\n",
       "  '71517',\n",
       "  '71284',\n",
       "  '415852',\n",
       "  '71404',\n",
       "  '71298',\n",
       "  '73630',\n",
       "  '71318',\n",
       "  '71348',\n",
       "  '71379',\n",
       "  '71647',\n",
       "  '71663',\n",
       "  '71673',\n",
       "  '71485',\n",
       "  '71222',\n",
       "  '71297',\n",
       "  '71347',\n",
       "  '71100',\n",
       "  '71133',\n",
       "  '71217',\n",
       "  '73696',\n",
       "  '73689',\n",
       "  '71407',\n",
       "  '73616',\n",
       "  '70537',\n",
       "  '70636',\n",
       "  '70375',\n",
       "  '71351',\n",
       "  '71977',\n",
       "  '70452',\n",
       "  '72031',\n",
       "  '72013',\n",
       "  '70645',\n",
       "  '71253',\n",
       "  '71363',\n",
       "  '70596',\n",
       "  '72430',\n",
       "  '71201',\n",
       "  '72460',\n",
       "  '70488',\n",
       "  '71076',\n",
       "  '70604',\n",
       "  '73695',\n",
       "  '70143',\n",
       "  '70248',\n",
       "  '71001',\n",
       "  '73615']}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 - env",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
